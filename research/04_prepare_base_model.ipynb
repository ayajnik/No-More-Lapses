{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"attention_weights\",\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"glorot_uniform\",\n",
    "                                 trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute attention scores\n",
    "        e = tf.matmul(inputs, self.W)\n",
    "        alpha = tf.nn.softmax(e, axis=1)\n",
    "        context = tf.reduce_sum(alpha * inputs, axis=1)\n",
    "        return context, tf.squeeze(alpha, -1)  # output attention weights too\n",
    "\n",
    "def build_attention_model(input_dim, num_classes, return_attention=False):\n",
    "    inputs = tf.keras.Input(shape=(input_dim,))\n",
    "    x = tf.expand_dims(inputs, axis=1)\n",
    "\n",
    "    attention_layer = AttentionLayer()\n",
    "    attention_output, attention_weights = attention_layer(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(attention_output)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    if return_attention:\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=[output, attention_weights])\n",
    "    else:\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Entity method for model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelPreparationConfig:\n",
    "    root_dir: Path\n",
    "    training_independent_data_path: Path\n",
    "    training_dependent_data_path: Path\n",
    "    model_saved_path: Path\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    optimizer: str\n",
    "    loss: str\n",
    "    metrics: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.No_More_Lapses.constants import *\n",
    "from src.No_More_Lapses.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_model_preparation_config(self) -> ModelPreparationConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.training_hyperparameters\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = ModelPreparationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            training_independent_data_path = config.training_independent_data_path,\n",
    "            training_dependent_data_path = config.training_dependent_data_path,\n",
    "            model_saved_path = config.model_saved_path,\n",
    "            epochs=params.EPOCHS,\n",
    "            batch_size=params.BATCH_SIZE,\n",
    "            optimizer=params.OPTIMIZER,\n",
    "            loss=params.LOSS,\n",
    "            metrics=params.METRICS\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the configuration manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 11:51:43,916: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-03-24 11:51:43,919: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-24 11:51:43,920: INFO: common: created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "a = ConfigurationManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 11:51:56,520: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelPreparationConfig(root_dir='artifacts/model_trainer', training_independent_data_path='artifacts/transformed_data/trainining_data/X_train.csv', training_dependent_data_path='artifacts/transformed_data/trainining_data/y_train.csv', model_saved_path='artifacts/model_trainer/attention_model.h5', epochs=20, batch_size=32, optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_model_preparation_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.No_More_Lapses import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPreparation:\n",
    "    \n",
    "    def __init__(self, config: ModelPreparationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def trainModel(self):\n",
    "        X_train = pd.read_csv(self.config.training_independent_data_path)\n",
    "        y_train = pd.read_csv(self.config.training_dependent_data_path)\n",
    "        logger.info(\"Train data loaded\")\n",
    "\n",
    "        X_train = X_train.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "        y_train = y_train.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "        logger.info(\"Removing the index column\")\n",
    "\n",
    "        y_series = y_train[\"POLICY STATUS\"]  # explicitly get the column\n",
    "        num_classes = len(y_series.unique())\n",
    "\n",
    "        # Step 4: Convert to categorical\n",
    "        y_encoded = tf.keras.utils.to_categorical(y_series, num_classes)\n",
    "        logger.info(\"Converted y to one-hot encoding\")\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_train)\n",
    "        logger.info(\"Applied Standard Scaler to scale down the values in the same range to avoid gradient boosting or biases\")\n",
    "\n",
    "        model = build_attention_model(input_dim=X_scaled.shape[1], num_classes=num_classes, return_attention=False)\n",
    "\n",
    "\n",
    "        model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "            )\n",
    "        \n",
    "        model.fit(X_scaled, y_encoded, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "        attention_model = build_attention_model(input_dim=X_scaled.shape[1], num_classes=num_classes, return_attention=True)\n",
    "        attention_model.set_weights(model.get_weights())\n",
    "        # Save model and scaler\n",
    "        model.save(self.config.model_saved_path)\n",
    "        return model, scaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model (test version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:15:28,357: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "model_caller = ModelPreparation(config=a.get_model_preparation_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:15:29,898: INFO: 2486981150: Train data loaded]\n",
      "[2025-03-24 12:15:29,917: INFO: 2486981150: Removing the index column]\n",
      "[2025-03-24 12:15:29,925: INFO: 2486981150: Converted y to one-hot encoding]\n",
      "[2025-03-24 12:15:29,973: INFO: 2486981150: Applied Standard Scaler to scale down the values in the same range to avoid gradient boosting or biases]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 12:15:30.311074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.8534 - accuracy: 0.6328\n",
      "Epoch 2/20\n",
      "12324/12324 [==============================] - 222s 18ms/step - loss: 0.7677 - accuracy: 0.6680\n",
      "Epoch 3/20\n",
      "12324/12324 [==============================] - 223s 18ms/step - loss: 0.7387 - accuracy: 0.6804\n",
      "Epoch 4/20\n",
      "12324/12324 [==============================] - 224s 18ms/step - loss: 0.7195 - accuracy: 0.6880\n",
      "Epoch 5/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.7058 - accuracy: 0.6931\n",
      "Epoch 6/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6962 - accuracy: 0.6967\n",
      "Epoch 7/20\n",
      "12324/12324 [==============================] - 224s 18ms/step - loss: 0.6878 - accuracy: 0.6997\n",
      "Epoch 8/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6819 - accuracy: 0.7023\n",
      "Epoch 9/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6769 - accuracy: 0.7043\n",
      "Epoch 10/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6723 - accuracy: 0.7061\n",
      "Epoch 11/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6680 - accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "12324/12324 [==============================] - 229s 19ms/step - loss: 0.6647 - accuracy: 0.7094\n",
      "Epoch 13/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6617 - accuracy: 0.7105\n",
      "Epoch 14/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6593 - accuracy: 0.7112\n",
      "Epoch 15/20\n",
      "12324/12324 [==============================] - 224s 18ms/step - loss: 0.6565 - accuracy: 0.7126\n",
      "Epoch 16/20\n",
      "12324/12324 [==============================] - 226s 18ms/step - loss: 0.6541 - accuracy: 0.7133\n",
      "Epoch 17/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6515 - accuracy: 0.7143\n",
      "Epoch 18/20\n",
      "12324/12324 [==============================] - 226s 18ms/step - loss: 0.6495 - accuracy: 0.7158\n",
      "Epoch 19/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6477 - accuracy: 0.7156\n",
      "Epoch 20/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6460 - accuracy: 0.7169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x2cc1eabe0>, StandardScaler())"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_caller.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_independent_data_path='artifacts/transformed_data/trainining_data/X_train.csv'\n",
    "training_dependent_data_path='artifacts/transformed_data/trainining_data/y_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 14:15:31,894: INFO: 3808260860: Converted y to one-hot encoding]\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(training_independent_data_path)\n",
    "y = pd.read_csv(training_dependent_data_path)\n",
    "\n",
    "X_train = X.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "y_train = y.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "\n",
    "y_series = y_train[\"POLICY STATUS\"]  # explicitly get the column\n",
    "num_classes = len(y_series.unique())\n",
    "\n",
    "# Step 4: Convert to categorical\n",
    "y_encoded = tf.keras.utils.to_categorical(y_series, num_classes)\n",
    "logger.info(\"Converted y to one-hot encoding\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
