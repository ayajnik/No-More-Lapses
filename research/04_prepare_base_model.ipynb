{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"attention_weights\",\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"glorot_uniform\",\n",
    "                                 trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute attention scores\n",
    "        e = tf.matmul(inputs, self.W)\n",
    "        alpha = tf.nn.softmax(e, axis=1)\n",
    "        context = tf.reduce_sum(alpha * inputs, axis=1)\n",
    "        return context, tf.squeeze(alpha, -1)  # output attention weights too\n",
    "\n",
    "def build_attention_model(input_dim, num_classes, return_attention=False):\n",
    "    inputs = tf.keras.Input(shape=(input_dim,))\n",
    "    x = tf.expand_dims(inputs, axis=1)\n",
    "\n",
    "    attention_layer = AttentionLayer()\n",
    "    attention_output, attention_weights = attention_layer(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(attention_output)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    if return_attention:\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=[output, attention_weights])\n",
    "    else:\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Entity method for model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelPreparationConfig:\n",
    "    root_dir: Path\n",
    "    training_independent_data_path: Path\n",
    "    training_dependent_data_path: Path\n",
    "    model_saved_path: Path\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    optimizer: str\n",
    "    loss: str\n",
    "    metrics: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.No_More_Lapses.constants import *\n",
    "from src.No_More_Lapses.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_model_preparation_config(self) -> ModelPreparationConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.training_hyperparameters\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = ModelPreparationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            training_independent_data_path = config.training_independent_data_path,\n",
    "            training_dependent_data_path = config.training_dependent_data_path,\n",
    "            model_saved_path = config.model_saved_path,\n",
    "            epochs=params.EPOCHS,\n",
    "            batch_size=params.BATCH_SIZE,\n",
    "            optimizer=params.OPTIMIZER,\n",
    "            loss=params.LOSS,\n",
    "            metrics=params.METRICS\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the configuration manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 11:51:43,916: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-03-24 11:51:43,919: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-24 11:51:43,920: INFO: common: created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "a = ConfigurationManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 11:51:56,520: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelPreparationConfig(root_dir='artifacts/model_trainer', training_independent_data_path='artifacts/transformed_data/trainining_data/X_train.csv', training_dependent_data_path='artifacts/transformed_data/trainining_data/y_train.csv', model_saved_path='artifacts/model_trainer/attention_model.h5', epochs=20, batch_size=32, optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_model_preparation_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.No_More_Lapses import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPreparation:\n",
    "    \n",
    "    def __init__(self, config: ModelPreparationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def trainModel(self):\n",
    "        X_train = pd.read_csv(self.config.training_independent_data_path)\n",
    "        y_train = pd.read_csv(self.config.training_dependent_data_path)\n",
    "        logger.info(\"Train data loaded\")\n",
    "\n",
    "        X_train = X_train.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "        y_train = y_train.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "        logger.info(\"Removing the index column\")\n",
    "\n",
    "        y_series = y_train[\"POLICY STATUS\"]  # explicitly get the column\n",
    "        num_classes = len(y_series.unique())\n",
    "\n",
    "        # Step 4: Convert to categorical\n",
    "        y_encoded = tf.keras.utils.to_categorical(y_series, num_classes)\n",
    "        logger.info(\"Converted y to one-hot encoding\")\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_train)\n",
    "        logger.info(\"Applied Standard Scaler to scale down the values in the same range to avoid gradient boosting or biases\")\n",
    "\n",
    "        model = build_attention_model(input_dim=X_scaled.shape[1], num_classes=num_classes, return_attention=False)\n",
    "\n",
    "\n",
    "        model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "            )\n",
    "        \n",
    "        model.fit(X_scaled, y_encoded, epochs=self.config.epochs, batch_size=self.config.batch_size)\n",
    "        attention_model = build_attention_model(input_dim=X_scaled.shape[1], num_classes=num_classes, return_attention=True)\n",
    "        attention_model.set_weights(model.get_weights())\n",
    "        # Save model and scaler\n",
    "        model.save(self.config.model_saved_path)\n",
    "        return model, scaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model (test version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:15:28,357: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "model_caller = ModelPreparation(config=a.get_model_preparation_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:15:29,898: INFO: 2486981150: Train data loaded]\n",
      "[2025-03-24 12:15:29,917: INFO: 2486981150: Removing the index column]\n",
      "[2025-03-24 12:15:29,925: INFO: 2486981150: Converted y to one-hot encoding]\n",
      "[2025-03-24 12:15:29,973: INFO: 2486981150: Applied Standard Scaler to scale down the values in the same range to avoid gradient boosting or biases]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 12:15:30.311074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.8534 - accuracy: 0.6328\n",
      "Epoch 2/20\n",
      "12324/12324 [==============================] - 222s 18ms/step - loss: 0.7677 - accuracy: 0.6680\n",
      "Epoch 3/20\n",
      "12324/12324 [==============================] - 223s 18ms/step - loss: 0.7387 - accuracy: 0.6804\n",
      "Epoch 4/20\n",
      "12324/12324 [==============================] - 224s 18ms/step - loss: 0.7195 - accuracy: 0.6880\n",
      "Epoch 5/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.7058 - accuracy: 0.6931\n",
      "Epoch 6/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6962 - accuracy: 0.6967\n",
      "Epoch 7/20\n",
      "12324/12324 [==============================] - 224s 18ms/step - loss: 0.6878 - accuracy: 0.6997\n",
      "Epoch 8/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6819 - accuracy: 0.7023\n",
      "Epoch 9/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6769 - accuracy: 0.7043\n",
      "Epoch 10/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6723 - accuracy: 0.7061\n",
      "Epoch 11/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6680 - accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "12324/12324 [==============================] - 229s 19ms/step - loss: 0.6647 - accuracy: 0.7094\n",
      "Epoch 13/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6617 - accuracy: 0.7105\n",
      "Epoch 14/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6593 - accuracy: 0.7112\n",
      "Epoch 15/20\n",
      "12324/12324 [==============================] - 224s 18ms/step - loss: 0.6565 - accuracy: 0.7126\n",
      "Epoch 16/20\n",
      "12324/12324 [==============================] - 226s 18ms/step - loss: 0.6541 - accuracy: 0.7133\n",
      "Epoch 17/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6515 - accuracy: 0.7143\n",
      "Epoch 18/20\n",
      "12324/12324 [==============================] - 226s 18ms/step - loss: 0.6495 - accuracy: 0.7158\n",
      "Epoch 19/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6477 - accuracy: 0.7156\n",
      "Epoch 20/20\n",
      "12324/12324 [==============================] - 225s 18ms/step - loss: 0.6460 - accuracy: 0.7169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x2cc1eabe0>, StandardScaler())"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_caller.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_independent_data_path='artifacts/transformed_data/trainining_data/X_train.csv'\n",
    "training_dependent_data_path='artifacts/transformed_data/trainining_data/y_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 14:15:31,894: INFO: 3808260860: Converted y to one-hot encoding]\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(training_independent_data_path)\n",
    "y = pd.read_csv(training_dependent_data_path)\n",
    "\n",
    "X_train = X.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "y_train = y.drop(columns=['Unnamed: 0'],errors='ignore')\n",
    "\n",
    "y_series = y_train[\"POLICY STATUS\"]  # explicitly get the column\n",
    "num_classes = len(y_series.unique())\n",
    "\n",
    "# Step 4: Convert to categorical\n",
    "y_encoded = tf.keras.utils.to_categorical(y_series, num_classes)\n",
    "logger.info(\"Converted y to one-hot encoding\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.17.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.17.2 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.17.2-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (3.5)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (3.7.3)\n",
      "Requirement already satisfied: numpy<3 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (1.23.2)\n",
      "Requirement already satisfied: pandas<3 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (2.0.3)\n",
      "Collecting pyarrow<18,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (1.3.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (1.10.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading SQLAlchemy-2.0.39-cp38-cp38-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow) (3.1.2)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (8.1.7)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading databricks_sdk-0.47.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (6.8.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging<25 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (23.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (3.20.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from mlflow-skinny==2.17.2->mlflow) (2.31.0)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: importlib-resources in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (4.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<4->mlflow)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from matplotlib<4->mlflow) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from matplotlib<4->mlflow) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from matplotlib<4->mlflow) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from matplotlib<4->mlflow) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from matplotlib<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from pandas<3->mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (2.23.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.2->mlflow) (3.17.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (2023.7.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.15.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/ayushyajnik/tensorflow-test/env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.5.0)\n",
      "Downloading mlflow-2.17.2-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.2-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp38-cp38-macosx_11_0_arm64.whl (27.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.39-cp38-cp38-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.47.0-py3-none-any.whl (681 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.0/681.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: sqlparse, sqlalchemy, smmap, pyarrow, Mako, itsdangerous, gunicorn, graphql-core, deprecated, cloudpickle, blinker, opentelemetry-api, graphql-relay, gitdb, Flask, docker, alembic, opentelemetry-semantic-conventions, graphene, gitpython, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.0.3 Mako-1.3.9 alembic-1.14.1 blinker-1.8.2 cloudpickle-3.1.1 databricks-sdk-0.47.0 deprecated-1.2.18 docker-7.1.0 gitdb-4.0.12 gitpython-3.1.44 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 itsdangerous-2.2.0 mlflow-2.17.2 mlflow-skinny-2.17.2 opentelemetry-api-1.31.1 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 pyarrow-17.0.0 smmap-5.0.2 sqlalchemy-2.0.39 sqlparse-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import mlflow\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/24 14:58:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'baseline_RandomForestClassifier'.\n",
      "Created version '1' of model 'baseline_RandomForestClassifier'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:mlruns\")\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_scaled, y_series)\n",
    "y_pred = clf.predict(X_scaled)\n",
    "acc = accuracy_score(y_series, y_pred)\n",
    "report=classification_report(y_series, y_pred)\n",
    "joblib.dump(clf, 'artifacts/model_trainer/baseline_model.h5')\n",
    "\n",
    "with open(\"logs/rf_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "with open(\"logs/rf_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "with mlflow.start_run(run_name=\"baseline_RandomForestClassifier\"):\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.sklearn.log_model(clf, \"model\", registered_model_name=\"baseline_RandomForestClassifier\")\n",
    "    mlflow.log_artifact('artifacts/model_trainer')\n",
    "    mlflow.log_artifact(\"artifacts/model_trainer/rf_report.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
